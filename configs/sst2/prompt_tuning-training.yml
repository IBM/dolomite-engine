datasets:
  - class_name: SST2Dataset
    data_name: sst2
    input_format: "\n__input__\nSentiment:"
    output_format: " __output__"
    data_sampling_ratio: 1
    max_input_tokens: 1024
    max_output_tokens: 128

model_args:
  model_name: bigscience/bloom-560m
  model_class: AutoModelForCausalLM

tuning_args:
  tuning_method: prompt_tuning
  prompt_tuning_args:
    prompt_tuning_init: TEXT
    prompt_tuning_init_text: "Classify the sentiment of the sentence:"
    num_virtual_tokens: 8

save_args:
  save_path: checkpoints/prompt_tuning
  save_interval: 500

training_parameters:
  num_training_steps: 4000
  eval_interval: 500
  micro_batch_size: 8

optimizer_args:
  class_name: ApexFusedAdam
  class_args:
    lr: 1e-5
    weight_decay: 0.1
    betas:
      - 0.9
      - 0.95
    eps: 1e-10

lr_scheduler_args:
  lr_decay_style: cosine

mixed_precision_args:
  dtype: bf16
